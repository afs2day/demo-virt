= Migrating Virtual Machines from VMware to OpenShift using MTV

https://red.ht/mtv-docs[Migration Toolkit for Virtualization]

== Install the Migration Toolkit for Virtualization Operator

* Install the MTV Operator

[source,bash]
----
$ oc apply -k operator/overlays/release-v2.4
namespace/openshift-mtv created
operatorgroup.operators.coreos.com/migration created
subscription.operators.coreos.com/mtv-operator created
----

* Ready the provider credentials in link:instance/base/secrets/[instance/base/secrets/].

* Create a Forklift resource to start MTV services

[source,bash]
----
$ oc apply -k instance/base
secret/provider-creds created
forkliftcontroller.forklift.konveyor.io/forklift-controller created
----

* Refresh the OpenShift web console and a new Migration item will appear.

* Confirm that multiple pods are running

[source,bash]
----
$ oc get pods -n openshift-mtv
NAME                                                    READY   STATUS    RESTARTS   AGE
forklift-api-67d4b8c5b7-crbzs                           1/1     Running   0          2m13s
forklift-controller-985596cc4-mswtc                     2/2     Running   0          2m24s
forklift-must-gather-api-6d554d9d75-jwj7l               1/1     Running   0          118s
forklift-operator-6d574b99d9-nwcf6                      1/1     Running   0          5m6s
forklift-ui-plugin-58bc5df894-wpgqb                     1/1     Running   0          105s
forklift-validation-79b57595bf-ngjkb                    1/1     Running   0          2m3s
forklift-volume-populator-controller-5846bc88c7-n5nl8   1/1     Running   0          2m18s
----

== Build a VDDK Container Image

To migrate from vSphere, a VDDK image will be required.

Download the https://developer.vmware.com/web/sdk/7.0/vddk[VMware VDDK] tar.gz file and place it in migration directory. The steps below will automatically build and push to the cluster registry once it is exposed.

=== Expose OpenShift Cluster Registry

You may optionally https://docs.openshift.com/container-platform/latest/registry/securing-exposing-registry.html[expose the OpenShift cluster image registry] to store the VDDK image built in the following step.

[TIP]
If you do not expose the cluster registry, the VDDK image must be pushed to some other registry. You can do so by hand or using and the Makefile variables. The location must be updated in the `Provider` link:instance/overlays/lab/provider.yaml[provider.yaml].

* Expose the cluster registry and capture the URL

[source,bash]
----
oc patch configs.imageregistry.operator.openshift.io/cluster --patch '{"spec":{"defaultRoute":true}}' --type=merge

export REGISTRY=$(oc get route default-route -n openshift-image-registry --template='{{ .spec.host }}')
----

* Obtain a token for logging into the OpenShift registry.

[source,bash]
----
export REGISTRY_USER=builder # must not be 'system:admin'
export TOKEN=$(oc create token builder -n openshift-mtv)
----

* Login to the registry

[source,bash]
----
$ podman login -u $REGISTRY_USER -p $TOKEN $REGISTRY
Login Succeeded!
----

* Build and push vddk image to OpenShift registry. See link:Makefile[Makefile]

[source,bash]
----
$ cd vddk

$ make image
tar -xzf VMware-vix-disklib-7.0.3-20134304.x86_64.tar.gz
podman build . -t vddk:7.0.3-20134304 && \
        podman tag vddk:7.0.3-20134304 default-route-openshift-image-registry.apps.hub.lab.bewley.net/openshift-mtv/vddk:7.0.3-20134304 && \
        podman tag vddk:7.0.3-20134304 default-route-openshift-image-registry.apps.hub.lab.bewley.net/openshift-mtv/vddk:latest
STEP 1/5: FROM registry.access.redhat.com/ubi8/ubi-minimal
STEP 2/5: USER 1001
--> Using cache 122039dcf6243a95eb5b6b80247dbdf2d04de89701111c32f1ca32c03102ec1b
--> 122039dcf624
STEP 3/5: COPY vmware-vix-disklib-distrib /vmware-vix-disklib-distrib
--> Using cache 77ecf26236ab061e4f839dbc2001ddfe48a6a6580f6c767effc58621996101f9
--> 77ecf26236ab
STEP 4/5: RUN mkdir -p /opt
--> Using cache d5fe34a4b964d19205709a6bf00d13ac3fc8655b752f724c0f71ea32b2d1f760
--> d5fe34a4b964
STEP 5/5: ENTRYPOINT ["cp", "-r", "/vmware-vix-disklib-distrib", "/opt"]
--> Using cache 455fd246ee5833b19a0c8e919ea6ea7006f828e3873dfb590611f43a0b6142c8
COMMIT vddk:7.0.3-20134304
--> 455fd246ee58
Successfully tagged localhost/vddk:7.0.3-20134304
Successfully tagged default-route-openshift-image-registry.apps.hub.lab.bewley.net/openshift-mtv/vddk:7.0.3-20134304
Successfully tagged default-route-openshift-image-registry.apps.hub.lab.bewley.net/openshift-mtv/vddk:latest
455fd246ee5833b19a0c8e919ea6ea7006f828e3873dfb590611f43a0b6142c8

$  make push
podman push --tls-verify=false default-route-openshift-image-registry.apps.hub.lab.bewley.net/openshift-mtv/vddk:latest
Getting image source signatures
Copying blob sha256:3196904b95517fd70bece2220309675d2f98172e2e37fcfeb6e45e7badf6ebc8
Copying blob sha256:969795712c492f0c43031ce89dfb3d6ca2c08221fc28fb4479c7e0a370af7342
Copying blob sha256:0b474ab10c0960f9a901f530835176cd1c6ed2866c6bac8d56e9188308edf244
Copying config sha256:455fd246ee5833b19a0c8e919ea6ea7006f828e3873dfb590611f43a0b6142c8
Writing manifest to image destination
Storing signatures

$ cd ..
----

== Create a VMware Provider

Browse to Migration -> Providers for virtualization and https://access.redhat.com/documentation/en-us/migration_toolkit_for_virtualization/2.4/html/installing_and_using_the_migration_toolkit_for_virtualization/migrating-vms-web-console#adding-providers[Create a VMware provider] by hand or use Kustomize.

.Capture vCenter SHA1 Fingerprint
[IMPORTANT]
====
The provider will require the SHA1 fingerprint of the vCenter server certificate.

* Obtain the SHA-1 fingerprint for the vCenter certificate and write this value to link:instance/base/secrets/thumbprint[instance/base/secrets/thumbprint]
[source,bash]
----
$ echo | openssl s_client -connect vcenter.lab.bewley.net:443 2>/dev/null -showcerts \
       | openssl x509 -fingerprint -sha1 -noout
SHA1 Fingerprint=C2:6C:23:AA:0A:EE:30:25:B5:7D:EE:31:24:28:E7:4A:78:3E:A2:01
----
====

* Create VMware provider

[source,bash]
$ oc apply -k instance/overlays/lab/
rolebinding.rbac.authorization.k8s.io/allow-image-pullers created
secret/provider-creds configured
forkliftcontroller.forklift.konveyor.io/forklift-controller unchanged
provider.forklift.konveyor.io/lab created


*  Create storage and network mappings

[source,bash]
----
$ oc apply -k instance/overlays/lab
rolebinding.rbac.authorization.k8s.io/allow-image-pullers created
secret/provider-creds created
forkliftcontroller.forklift.konveyor.io/forklift-controller unchanged
networkmap.forklift.konveyor.io/netmap created
provider.forklift.konveyor.io/lab created
storagemap.forklift.konveyor.io/storemap created
----

image:img/provider.png[]

* Edit the provider and correct the credentials and certificate SHA-1 fingerprint if it is not already present.

image:img/provider-edit.png[]

* Status should now be Ready.

image:img/provider-ready.png[]

* Optionally select a Migration Network for the 'host' provider used by MTV. The default Management Network should function.

// Needs more testing. Setting a Migration network explicitly does not seem to be necessary.
// .**TBD**
// [WARNING]
// When the vNIC had an IP OpenShift integration with vSphere failed. Need more testing.

// image:img/mig-network-1.png[]

// image:img/mig-network-2.png[]

// .**ESXi Connectivity**
// [TIP]
// Ensure the vSphere host can be reached on the chosen migration network.
// image:img/add-vmkernel-nic.png[]

== Create Migration Plan

.TODO
* Verify a migration in a user nameapce